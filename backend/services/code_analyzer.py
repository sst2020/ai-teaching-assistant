"""
Advanced Code Quality Analyzer Service.

This module provides comprehensive code quality analysis including:
- Cyclomatic complexity calculation using radon
- Cognitive complexity detection
- Code duplication detection using AST
- Maintainability index calculation
"""
import ast
import uuid
import hashlib
import logging
from typing import List, Dict, Any, Optional, Tuple, Set
from datetime import datetime, timezone
from collections import defaultdict

from radon.complexity import cc_visit, cc_rank
from radon.metrics import mi_visit, h_visit
from radon.raw import analyze

from schemas.analysis import (
    CodeQualityResult, CodeQualityMetrics, FunctionComplexity,
    DuplicateCodeBlock, ComplexityGrade, MaintainabilityRating,
    AnalysisCodeRequest
)

logger = logging.getLogger(__name__)


def get_complexity_grade(complexity: int) -> ComplexityGrade:
    """Convert cyclomatic complexity to letter grade."""
    if complexity <= 5:
        return ComplexityGrade.A
    elif complexity <= 10:
        return ComplexityGrade.B
    elif complexity <= 20:
        return ComplexityGrade.C
    elif complexity <= 30:
        return ComplexityGrade.D
    elif complexity <= 40:
        return ComplexityGrade.E
    else:
        return ComplexityGrade.F


def get_maintainability_rating(mi: float) -> MaintainabilityRating:
    """Convert maintainability index to rating."""
    if mi >= 80:
        return MaintainabilityRating.EXCELLENT
    elif mi >= 60:
        return MaintainabilityRating.GOOD
    elif mi >= 40:
        return MaintainabilityRating.MODERATE
    elif mi >= 20:
        return MaintainabilityRating.POOR
    else:
        return MaintainabilityRating.VERY_POOR


class CognitiveComplexityVisitor(ast.NodeVisitor):
    """AST visitor to calculate cognitive complexity."""
    
    def __init__(self):
        self.complexity = 0
        self.nesting_level = 0
        self.max_nesting = 0
    
    def _increment(self, node, nesting_increment: bool = True):
        """Increment complexity with nesting penalty."""
        if nesting_increment:
            self.complexity += 1 + self.nesting_level
        else:
            self.complexity += 1
    
    def visit_If(self, node):
        self._increment(node)
        self.nesting_level += 1
        self.max_nesting = max(self.max_nesting, self.nesting_level)
        self.generic_visit(node)
        self.nesting_level -= 1
        
        # Handle elif as separate increment without nesting
        for child in node.orelse:
            if isinstance(child, ast.If):
                self.complexity += 1  # elif doesn't add nesting penalty
    
    def visit_For(self, node):
        self._increment(node)
        self.nesting_level += 1
        self.max_nesting = max(self.max_nesting, self.nesting_level)
        self.generic_visit(node)
        self.nesting_level -= 1
    
    def visit_While(self, node):
        self._increment(node)
        self.nesting_level += 1
        self.max_nesting = max(self.max_nesting, self.nesting_level)
        self.generic_visit(node)
        self.nesting_level -= 1
    
    def visit_ExceptHandler(self, node):
        self._increment(node)
        self.nesting_level += 1
        self.max_nesting = max(self.max_nesting, self.nesting_level)
        self.generic_visit(node)
        self.nesting_level -= 1
    
    def visit_BoolOp(self, node):
        # Each boolean operator adds to complexity
        self.complexity += len(node.values) - 1
        self.generic_visit(node)
    
    def visit_Lambda(self, node):
        self._increment(node, nesting_increment=False)
        self.generic_visit(node)
    
    def visit_comprehension(self, node):
        self._increment(node, nesting_increment=False)
        self.generic_visit(node)


def calculate_cognitive_complexity(func_node: ast.AST) -> Tuple[int, int]:
    """Calculate cognitive complexity for a function node.
    
    Returns:
        Tuple of (cognitive_complexity, max_nesting_depth)
    """
    visitor = CognitiveComplexityVisitor()
    visitor.visit(func_node)
    return visitor.complexity, visitor.max_nesting


class DuplicateDetector:
    """Detects duplicate code blocks using AST normalization."""
    
    def __init__(self, min_lines: int = 3):
        self.min_lines = min_lines
        self.blocks: Dict[str, List[Tuple[int, int, str]]] = defaultdict(list)
    
    def _normalize_node(self, node: ast.AST) -> str:
        """Normalize an AST node to a canonical string representation."""
        if isinstance(node, ast.Name):
            return "NAME"
        elif isinstance(node, ast.Constant):
            return f"CONST:{type(node.value).__name__}"
        elif isinstance(node, ast.Num):  # Python 3.7 compatibility
            return "NUM"
        elif isinstance(node, ast.Str):  # Python 3.7 compatibility
            return "STR"
        else:
            return node.__class__.__name__
    
    def _get_block_signature(self, nodes: List[ast.AST]) -> str:
        """Generate a signature for a block of AST nodes."""
        parts = []
        for node in nodes:
            parts.append(self._normalize_node(node))
            for child in ast.iter_child_nodes(node):
                parts.append(self._normalize_node(child))
        return hashlib.md5(":".join(parts).encode()).hexdigest()

    def find_duplicates(self, code: str) -> List[DuplicateCodeBlock]:
        """Find duplicate code blocks in the source code."""
        duplicates = []
        try:
            tree = ast.parse(code)
            lines = code.split('\n')

            # Extract all statement blocks
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef, ast.Module)):
                    body = getattr(node, 'body', [])

                    # Check sliding windows of statements
                    for i in range(len(body) - self.min_lines + 1):
                        block = body[i:i + self.min_lines]
                        if all(hasattr(n, 'lineno') for n in block):
                            start_line = block[0].lineno
                            end_line = getattr(block[-1], 'end_lineno', block[-1].lineno)
                            signature = self._get_block_signature(block)
                            snippet = '\n'.join(lines[start_line-1:end_line])
                            self.blocks[signature].append((start_line, end_line, snippet))

            # Find duplicates (signatures with multiple occurrences)
            block_id = 0
            for signature, occurrences in self.blocks.items():
                if len(occurrences) > 1:
                    block_id += 1
                    lines_list = [occ[0] for occ in occurrences]
                    snippet = occurrences[0][2]
                    duplicates.append(DuplicateCodeBlock(
                        block_id=block_id,
                        lines=lines_list,
                        code_snippet=snippet[:200] + "..." if len(snippet) > 200 else snippet,
                        similarity=100.0,
                        suggestion="è€ƒè™‘å°†é‡å¤ä»£ç æå–ä¸ºç‹¬ç«‹å‡½æ•°æˆ–æ–¹æ³•"
                    ))
        except SyntaxError:
            pass

        return duplicates


class CodeQualityAnalyzer:
    """Main code quality analyzer service."""

    def __init__(self, complexity_threshold: int = 10, nesting_threshold: int = 4):
        self.complexity_threshold = complexity_threshold
        self.nesting_threshold = nesting_threshold

    async def analyze(self, request: AnalysisCodeRequest) -> CodeQualityResult:
        """Perform comprehensive code quality analysis."""
        analysis_id = str(uuid.uuid4())
        code = request.code
        language = request.language

        # Initialize result
        functions: List[FunctionComplexity] = []
        issues: List[Dict[str, Any]] = []
        recommendations: List[str] = []

        # Calculate metrics
        metrics = CodeQualityMetrics()
        duplicates: List[DuplicateCodeBlock] = []

        if language == "python":
            try:
                # Use radon for cyclomatic complexity
                cc_results = cc_visit(code)

                # Calculate maintainability index
                try:
                    mi_score = mi_visit(code, True)
                    metrics.maintainability_index = round(mi_score, 2)
                    metrics.maintainability_rating = get_maintainability_rating(mi_score)
                except Exception:
                    metrics.maintainability_index = 50.0
                    metrics.maintainability_rating = MaintainabilityRating.MODERATE

                # Analyze raw metrics
                try:
                    raw = analyze(code)
                    metrics.total_lines = raw.loc
                    metrics.code_lines = raw.lloc
                    metrics.comment_lines = raw.comments
                    metrics.blank_lines = raw.blank
                    metrics.comment_ratio = round(
                        (raw.comments / raw.lloc * 100) if raw.lloc > 0 else 0, 2
                    )
                except Exception:
                    lines = code.split('\n')
                    metrics.total_lines = len(lines)

                # Parse AST for detailed analysis
                tree = ast.parse(code)

                # Analyze each function
                complexities = []
                cognitive_complexities = []

                for node in ast.walk(tree):
                    if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                        func_analysis = self._analyze_function(node, code, cc_results)
                        functions.append(func_analysis)
                        complexities.append(func_analysis.cyclomatic_complexity)
                        cognitive_complexities.append(func_analysis.cognitive_complexity)

                        # Check for issues
                        if func_analysis.is_complex:
                            issues.append({
                                "type": "high_complexity",
                                "severity": "warning",
                                "line": func_analysis.line_start,
                                "message": f"å‡½æ•° '{func_analysis.name}' åœˆå¤æ‚åº¦ä¸º {func_analysis.cyclomatic_complexity}ï¼Œè¶…è¿‡é˜ˆå€¼ {self.complexity_threshold}",
                                "suggestion": "è€ƒè™‘å°†å‡½æ•°æ‹†åˆ†ä¸ºæ›´å°çš„å‡½æ•°"
                            })

                        if func_analysis.nesting_depth > self.nesting_threshold:
                            issues.append({
                                "type": "deep_nesting",
                                "severity": "warning",
                                "line": func_analysis.line_start,
                                "message": f"å‡½æ•° '{func_analysis.name}' åµŒå¥—æ·±åº¦ä¸º {func_analysis.nesting_depth}ï¼Œè¶…è¿‡é˜ˆå€¼ {self.nesting_threshold}",
                                "suggestion": "ä½¿ç”¨æå‰è¿”å›æˆ–æå–å­å‡½æ•°æ¥å‡å°‘åµŒå¥—"
                            })

                # Update metrics
                if complexities:
                    metrics.avg_cyclomatic_complexity = round(sum(complexities) / len(complexities), 2)
                    metrics.max_cyclomatic_complexity = max(complexities)
                    metrics.total_functions = len(functions)
                    metrics.complex_functions = sum(1 for c in complexities if c > self.complexity_threshold)

                if cognitive_complexities:
                    metrics.avg_cognitive_complexity = round(sum(cognitive_complexities) / len(cognitive_complexities), 2)
                    metrics.max_cognitive_complexity = max(cognitive_complexities)
                    metrics.deep_nesting_count = sum(1 for f in functions if f.nesting_depth > self.nesting_threshold)

                # Detect duplicates
                detector = DuplicateDetector()
                duplicates = detector.find_duplicates(code)
                metrics.duplicate_blocks = len(duplicates)

                if duplicates:
                    total_dup_lines = sum(len(d.lines) for d in duplicates)
                    metrics.duplication_percentage = round(
                        (total_dup_lines / metrics.total_lines * 100) if metrics.total_lines > 0 else 0, 2
                    )

            except SyntaxError as e:
                issues.append({
                    "type": "syntax_error",
                    "severity": "error",
                    "line": getattr(e, 'lineno', 1),
                    "message": f"è¯­æ³•é”™è¯¯: {str(e)}",
                    "suggestion": "è¯·ä¿®å¤è¯­æ³•é”™è¯¯åé‡æ–°åˆ†æ"
                })

        # Generate recommendations
        recommendations = self._generate_recommendations(metrics, functions, duplicates)

        # Calculate overall score
        score = self._calculate_score(metrics, issues)
        grade = self._get_grade(score)

        # Generate summary
        summary = self._generate_summary(metrics, len(issues), len(duplicates))

        return CodeQualityResult(
            analysis_id=analysis_id,
            analyzed_at=datetime.now(timezone.utc),
            language=language,
            score=score,
            grade=grade,
            metrics=metrics,
            functions=functions,
            duplicates=duplicates,
            issues=issues,
            summary=summary,
            recommendations=recommendations
        )

    def _analyze_function(
        self, node: ast.AST, code: str, cc_results: List
    ) -> FunctionComplexity:
        """Analyze a single function."""
        name = node.name
        start_line = node.lineno
        end_line = getattr(node, 'end_lineno', start_line + 10)

        # Get cyclomatic complexity from radon results
        cc = 1
        for block in cc_results:
            if block.name == name and block.lineno == start_line:
                cc = block.complexity
                break

        # Calculate cognitive complexity
        cog_complexity, max_nesting = calculate_cognitive_complexity(node)

        # Count parameters
        params = len(node.args.args) if hasattr(node, 'args') else 0

        # Lines of code
        loc = end_line - start_line + 1

        # Generate suggestions
        suggestions = []
        if cc > self.complexity_threshold:
            suggestions.append(f"åœˆå¤æ‚åº¦ {cc} è¿‡é«˜ï¼Œå»ºè®®æ‹†åˆ†å‡½æ•°")
        if max_nesting > self.nesting_threshold:
            suggestions.append(f"åµŒå¥—æ·±åº¦ {max_nesting} è¿‡æ·±ï¼Œå»ºè®®ä½¿ç”¨æå‰è¿”å›")
        if params > 5:
            suggestions.append(f"å‚æ•°æ•°é‡ {params} è¿‡å¤šï¼Œå»ºè®®ä½¿ç”¨é…ç½®å¯¹è±¡")
        if loc > 50:
            suggestions.append(f"å‡½æ•°è¿‡é•¿ ({loc} è¡Œ)ï¼Œå»ºè®®æ‹†åˆ†")

        return FunctionComplexity(
            name=name,
            line_start=start_line,
            line_end=end_line,
            cyclomatic_complexity=cc,
            cognitive_complexity=cog_complexity,
            grade=get_complexity_grade(cc),
            is_complex=cc > self.complexity_threshold,
            nesting_depth=max_nesting,
            parameters=params,
            lines_of_code=loc,
            suggestions=suggestions
        )

    def _calculate_score(self, metrics: CodeQualityMetrics, issues: List) -> float:
        """Calculate overall quality score."""
        score = 100.0

        # Deduct for complexity
        if metrics.max_cyclomatic_complexity > 20:
            score -= 15
        elif metrics.max_cyclomatic_complexity > 10:
            score -= 8

        # Deduct for maintainability
        if metrics.maintainability_index < 40:
            score -= 15
        elif metrics.maintainability_index < 60:
            score -= 8

        # Deduct for duplicates
        if metrics.duplicate_blocks > 5:
            score -= 10
        elif metrics.duplicate_blocks > 0:
            score -= 5

        # Deduct for issues
        for issue in issues:
            if issue.get("severity") == "error":
                score -= 10
            elif issue.get("severity") == "warning":
                score -= 3

        return max(0, min(100, round(score, 1)))

    def _get_grade(self, score: float) -> str:
        """Convert score to letter grade."""
        if score >= 90:
            return "A"
        elif score >= 80:
            return "B"
        elif score >= 70:
            return "C"
        elif score >= 60:
            return "D"
        else:
            return "F"

    def _generate_recommendations(
        self, metrics: CodeQualityMetrics,
        functions: List[FunctionComplexity],
        duplicates: List[DuplicateCodeBlock]
    ) -> List[str]:
        """Generate improvement recommendations."""
        recommendations = []

        if metrics.max_cyclomatic_complexity > 15:
            recommendations.append(
                f"ğŸ“Š é‡æ„å¤æ‚å‡½æ•° - æœ€é«˜åœˆå¤æ‚åº¦ä¸º {metrics.max_cyclomatic_complexity}ï¼Œå»ºè®®æ‹†åˆ†ä¸ºæ›´å°çš„å‡½æ•°"
            )

        if metrics.maintainability_index < 60:
            recommendations.append(
                f"ğŸ”§ æé«˜å¯ç»´æŠ¤æ€§ - å½“å‰å¯ç»´æŠ¤æ€§æŒ‡æ•°ä¸º {metrics.maintainability_index:.1f}ï¼Œ"
                "å»ºè®®ç®€åŒ–ä»£ç ç»“æ„ã€æ·»åŠ æ³¨é‡Š"
            )

        if metrics.deep_nesting_count > 0:
            recommendations.append(
                f"ğŸ”„ å‡å°‘åµŒå¥—æ·±åº¦ - æœ‰ {metrics.deep_nesting_count} ä¸ªå‡½æ•°åµŒå¥—è¿‡æ·±ï¼Œ"
                "å»ºè®®ä½¿ç”¨æå‰è¿”å›æˆ–æå–æ–¹æ³•"
            )

        if duplicates:
            recommendations.append(
                f"â™»ï¸ æ¶ˆé™¤é‡å¤ä»£ç  - å‘ç° {len(duplicates)} å¤„é‡å¤ä»£ç å—ï¼Œ"
                "å»ºè®®æå–ä¸ºå¯å¤ç”¨çš„å‡½æ•°"
            )

        if metrics.comment_ratio < 10:
            recommendations.append(
                f"ğŸ“ å¢åŠ æ³¨é‡Š - å½“å‰æ³¨é‡Šæ¯”ä¾‹ä¸º {metrics.comment_ratio:.1f}%ï¼Œ"
                "å»ºè®®æ·»åŠ æ›´å¤šæ–‡æ¡£è¯´æ˜"
            )

        complex_funcs = [f for f in functions if f.is_complex]
        if complex_funcs:
            names = ", ".join(f.name for f in complex_funcs[:3])
            recommendations.append(
                f"âš ï¸ å…³æ³¨é«˜å¤æ‚åº¦å‡½æ•°: {names}"
            )

        if not recommendations:
            recommendations.append("âœ… ä»£ç è´¨é‡è‰¯å¥½ï¼ç»§ç»­ä¿æŒã€‚")

        return recommendations

    def _generate_summary(
        self, metrics: CodeQualityMetrics,
        issue_count: int,
        duplicate_count: int
    ) -> str:
        """Generate analysis summary."""
        parts = []

        parts.append(f"åˆ†æäº† {metrics.total_functions} ä¸ªå‡½æ•°")
        parts.append(f"å¹³å‡åœˆå¤æ‚åº¦ {metrics.avg_cyclomatic_complexity:.1f}")
        parts.append(f"å¯ç»´æŠ¤æ€§æŒ‡æ•° {metrics.maintainability_index:.1f} ({metrics.maintainability_rating.value})")

        if metrics.complex_functions > 0:
            parts.append(f"å‘ç° {metrics.complex_functions} ä¸ªé«˜å¤æ‚åº¦å‡½æ•°")

        if duplicate_count > 0:
            parts.append(f"æ£€æµ‹åˆ° {duplicate_count} å¤„é‡å¤ä»£ç ")

        if issue_count > 0:
            parts.append(f"å…± {issue_count} ä¸ªé—®é¢˜éœ€è¦å…³æ³¨")

        return "ã€‚".join(parts) + "ã€‚"


# Create singleton instance
code_quality_analyzer = CodeQualityAnalyzer()

