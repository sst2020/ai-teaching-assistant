# AI æœåŠ¡é…ç½®ä¸ä½¿ç”¨è¯´æ˜

## ğŸ“Š å½“å‰é…ç½®çŠ¶æ€æ€»ç»“

### âœ… å½“å‰ä½¿ç”¨çš„ AI Provider
**DeepSeek** (å·²å¯ç”¨å¹¶é…ç½®)

### ğŸ”‘ é…ç½®è¯¦æƒ…
```env
USE_DEEPSEEK=true
DEEPSEEK_API_KEY=sk-abf377836ab548169bf609f6ba675e2b
DEEPSEEK_API_BASE=https://api.deepseek.com/v1
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_TEMPERATURE=0.7
DEEPSEEK_MAX_TOKENS=2000
DEEPSEEK_TIMEOUT=60
DEEPSEEK_MAX_RETRIES=3
DEEPSEEK_RETRY_DELAY=1.0
```

---

## ğŸ—ï¸ AI Provider æ¶æ„

### æ”¯æŒçš„ AI æä¾›å•†

#### 1. **DeepSeek** (å½“å‰ä½¿ç”¨)
- **ä¼˜å…ˆçº§**: æœ€é«˜ (USE_DEEPSEEK=true)
- **API å…¼å®¹æ€§**: OpenAI-compatible API
- **æ¨¡å‹**: deepseek-chat, deepseek-reasoner
- **ç‰¹ç‚¹**: 
  - ä¸­æ–‡ä¼˜åŒ–
  - æµå¼å“åº”æ”¯æŒ
  - é‡è¯•æœºåˆ¶
  - è¯¦ç»†æ—¥å¿—è®°å½•
- **ä½¿ç”¨åœºæ™¯**: 
  - ä»£ç åé¦ˆç”Ÿæˆ (ä¸­æ–‡)
  - å­¦ç”Ÿé—®ç­” (ä¸­æ–‡)
  - é—®é¢˜åˆ†ç±»
  - æŠ¥å‘Šåˆ†æ

#### 2. **FastChat** (æœ¬åœ°éƒ¨ç½²)
- **ä¼˜å…ˆçº§**: ç¬¬äºŒ (USE_FASTCHAT=true)
- **API å…¼å®¹æ€§**: OpenAI-compatible API
- **æ¨¡å‹**: qwen2.5-7b (å¯é…ç½®)
- **ç‰¹ç‚¹**:
  - æœ¬åœ°éƒ¨ç½²ï¼Œæ•°æ®éšç§
  - æ—  API è´¹ç”¨
  - ä¸­æ–‡ä¼˜åŒ–
- **ä½¿ç”¨åœºæ™¯**: 
  - ç¦»çº¿ç¯å¢ƒ
  - æ•°æ®æ•æ„Ÿåœºæ™¯
  - æˆæœ¬æ§åˆ¶

#### 3. **OpenAI** (å¤‡ç”¨)
- **ä¼˜å…ˆçº§**: ç¬¬ä¸‰ (é»˜è®¤)
- **API**: å®˜æ–¹ OpenAI API
- **æ¨¡å‹**: gpt-4, gpt-3.5-turbo
- **ç‰¹ç‚¹**:
  - é«˜è´¨é‡å“åº”
  - è‹±æ–‡ä¼˜åŒ–
- **ä½¿ç”¨åœºæ™¯**:
  - è‹±æ–‡æ•™å­¦
  - é«˜çº§ä»£ç åˆ†æ

#### 4. **Local LLM** (å ä½ç¬¦)
- **ä¼˜å…ˆçº§**: æœ€ä½
- **å®ç°**: è§„åˆ™åŸºç¡€ + å…³é”®è¯åŒ¹é…
- **ç‰¹ç‚¹**:
  - æ— éœ€ API
  - åŠŸèƒ½æœ‰é™
- **ä½¿ç”¨åœºæ™¯**:
  - å¼€å‘æµ‹è¯•
  - æ¼”ç¤ºç¯å¢ƒ

---

## ğŸ”„ Provider é€‰æ‹©é€»è¾‘

### ä¼˜å…ˆçº§é¡ºåº (backend/services/ai_service.py:566-584)
```python
if settings.USE_DEEPSEEK:
    # ä½¿ç”¨ DeepSeek
    provider = DeepSeekProvider(config)
elif settings.USE_FASTCHAT:
    # ä½¿ç”¨ FastChat
    provider = FastChatProvider(config)
elif config.provider == AIProvider.OPENAI:
    # ä½¿ç”¨ OpenAI
    provider = OpenAIProvider(config)
else:
    # ä½¿ç”¨ Local LLM (fallback)
    provider = LocalLLMProvider(config)
```

### åˆ‡æ¢ Provider æ–¹æ³•

#### åˆ‡æ¢åˆ° OpenAI
```env
USE_DEEPSEEK=false
USE_FASTCHAT=false
OPENAI_API_KEY=your-openai-api-key
OPENAI_API_BASE=https://api.openai.com/v1
AI_MODEL=gpt-4
```

#### åˆ‡æ¢åˆ° FastChat
```env
USE_DEEPSEEK=false
USE_FASTCHAT=true
FASTCHAT_API_BASE=http://localhost:8000/v1
FASTCHAT_MODEL_NAME=qwen2.5-7b
```

#### åˆ‡æ¢åˆ° Local LLM
```env
USE_DEEPSEEK=false
USE_FASTCHAT=false
USE_LOCAL_LLM=true
```

---

## ğŸ¯ åŠŸèƒ½é›†æˆç‚¹

### 1. ä»£ç åé¦ˆç”Ÿæˆ
**è°ƒç”¨ä½ç½®**: `backend/api/ai.py:52-68`
```python
ai_result = await ai_service.generate_code_feedback(
    code=request.code,
    analysis_results={
        "overall_score": feedback.overall_score,
        "grade": feedback.overall_grade,
        "issues": [...]
    }
)
```

**ä½¿ç”¨åœºæ™¯**:
- å­¦ç”Ÿæäº¤ä»£ç åè‡ªåŠ¨ç”Ÿæˆåé¦ˆ
- æä¾›ä»£ç æ”¹è¿›å»ºè®®
- æŒ‡å‡ºä»£ç é£æ ¼å’Œå¤æ‚åº¦é—®é¢˜

### 2. å­¦ç”Ÿé—®ç­”
**è°ƒç”¨ä½ç½®**: `backend/services/qa_service.py:62-108`
```python
ai_answer = await self.ai.answer_question(request.question, context)
```

**ä½¿ç”¨åœºæ™¯**:
- å­¦ç”Ÿæé—®æ—¶è‡ªåŠ¨å›ç­”
- é—®é¢˜åˆ†ç±»å’Œä¼˜å…ˆçº§åˆ¤æ–­
- å†³å®šæ˜¯å¦éœ€è¦æ•™å¸ˆä»‹å…¥

### 3. æŠ¥å‘Šåˆ†æ
**è°ƒç”¨ä½ç½®**: `backend/services/report_analysis_service.py:498-513`
```python
response = await self.ai_service.generate_response(
    prompt=prompt,
    system_prompt="ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å­¦æœ¯æŠ¥å‘Šè¯„å®¡ä¸“å®¶...",
    max_tokens=2000,
    temperature=0.3
)
```

**ä½¿ç”¨åœºæ™¯**:
- åˆ†ææŠ¥å‘Šé€»è¾‘ç»“æ„
- è¯„ä¼°åˆ›æ–°æ€§
- è¯­è¨€è´¨é‡è¯„ä¼°

### 4. ä»£ç è¯„åˆ†
**è°ƒç”¨ä½ç½®**: `backend/services/grading_service.py:74-80`
```python
ai_feedback = await self.ai.generate_code_feedback(
    code=submission.content,
    analysis_results={...}
)
```

**ä½¿ç”¨åœºæ™¯**:
- è‡ªåŠ¨è¯„åˆ†
- ç”Ÿæˆè¯„åˆ†æŠ¥å‘Š
- æä¾›å­¦ä¹ å»ºè®®

---

## âš™ï¸ é…ç½®æœ€ä½³å®è·µ

### å¼€å‘ç¯å¢ƒ
```env
USE_DEEPSEEK=true
DEEPSEEK_TIMEOUT=60
DEEPSEEK_MAX_RETRIES=3
LOG_LEVEL=DEBUG
```

### ç”Ÿäº§ç¯å¢ƒ
```env
USE_DEEPSEEK=true
DEEPSEEK_TIMEOUT=30
DEEPSEEK_MAX_RETRIES=2
LOG_LEVEL=INFO
ENABLE_REQUEST_LOGGING=false
```

### ç¦»çº¿ç¯å¢ƒ
```env
USE_FASTCHAT=true
FASTCHAT_API_BASE=http://localhost:8000/v1
FASTCHAT_TIMEOUT=300
```

---

## ğŸ› å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: AI å“åº”è¶…æ—¶
**ç—‡çŠ¶**: `DeepSeekæœåŠ¡è¶…æ—¶: è¯·æ±‚è¶…è¿‡ 60 ç§’æœªå“åº”`
**è§£å†³æ–¹æ¡ˆ**:
1. å¢åŠ  `DEEPSEEK_TIMEOUT` å€¼
2. æ£€æŸ¥ç½‘ç»œè¿æ¥
3. å‡å°‘ `DEEPSEEK_MAX_TOKENS`

### é—®é¢˜ 2: API Key æ— æ•ˆ
**ç—‡çŠ¶**: `401 Unauthorized` æˆ– `Invalid API Key`
**è§£å†³æ–¹æ¡ˆ**:
1. éªŒè¯ API Key æ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥ API Key æ˜¯å¦è¿‡æœŸ
3. ç¡®è®¤ API Base URL æ­£ç¡®

### é—®é¢˜ 3: ä¸­æ–‡å“åº”ä¹±ç 
**ç—‡çŠ¶**: è¿”å›çš„ä¸­æ–‡æ˜¾ç¤ºä¸ºä¹±ç 
**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®è®¤ä½¿ç”¨ DeepSeek æˆ– FastChat (ä¸­æ–‡ä¼˜åŒ–)
2. æ£€æŸ¥æ•°æ®åº“ç¼–ç è®¾ç½®
3. éªŒè¯å‰ç«¯å­—ç¬¦ç¼–ç 

### é—®é¢˜ 4: å“åº”è´¨é‡å·®
**ç—‡çŠ¶**: AI å›ç­”ä¸å‡†ç¡®æˆ–ä¸ç›¸å…³
**è§£å†³æ–¹æ¡ˆ**:
1. è°ƒæ•´ `TEMPERATURE` å‚æ•° (0.3-0.9)
2. å¢åŠ  `MAX_TOKENS` å…è®¸æ›´é•¿å“åº”
3. ä¼˜åŒ– system_prompt å’Œ user_prompt
4. è€ƒè™‘åˆ‡æ¢åˆ°æ›´å¼ºå¤§çš„æ¨¡å‹

---

## ğŸ“ˆ æ€§èƒ½ç›‘æ§

### æŸ¥çœ‹ AI äº¤äº’ç»Ÿè®¡
```python
from services.ai_service import ai_service

stats = ai_service.get_interaction_stats()
print(stats)
# {
#     "total_interactions": 150,
#     "average_latency_ms": 2500,
#     "by_type": {
#         "generate_code_feedback": 50,
#         "answer_question": 80,
#         "categorize_question": 20
#     }
# }
```

### æ—¥å¿—ç›‘æ§
```bash
# æŸ¥çœ‹ AI è¯·æ±‚æ—¥å¿—
tail -f backend/logs/app.log | grep "DeepSeek API"
```

---

## ğŸ” å®‰å…¨å»ºè®®

1. **ä¸è¦æäº¤ API Key åˆ°ç‰ˆæœ¬æ§åˆ¶**
   - ä½¿ç”¨ `.env` æ–‡ä»¶
   - æ·»åŠ åˆ° `.gitignore`

2. **ä½¿ç”¨ç¯å¢ƒå˜é‡**
   - ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ç¯å¢ƒå˜é‡è€Œé `.env` æ–‡ä»¶
   - ä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡ (å¦‚ AWS Secrets Manager)

3. **é™åˆ¶ API ä½¿ç”¨**
   - è®¾ç½®åˆç†çš„ `MAX_TOKENS`
   - å®æ–½é€Ÿç‡é™åˆ¶
   - ç›‘æ§ API ä½¿ç”¨é‡

4. **æ•°æ®éšç§**
   - æ•æ„Ÿæ•°æ®ä½¿ç”¨æœ¬åœ° LLM (FastChat)
   - ä¸è¦å°†å­¦ç”Ÿä¸ªäººä¿¡æ¯å‘é€åˆ°å¤–éƒ¨ API
   - éµå®ˆæ•°æ®ä¿æŠ¤æ³•è§„


